{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redis LangChain Llama-2 eCommerce Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-h_nDGp3Kdf",
    "outputId": "94191443-3844-4c1d-a26f-7619d976a55b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.0.264)\n",
      "Requirement already satisfied: redis==4.5.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.5.3)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.25.2)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.0.3)\n",
      "Requirement already satisfied: gdown in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (4.7.1)\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in ./venv/lib/python3.10/site-packages (from redis==4.5.3->-r requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 1)) (1.4.49)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 1)) (3.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in ./venv/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 1)) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in ./venv/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 1)) (0.0.22)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in ./venv/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 1)) (2.8.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in ./venv/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in ./venv/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 1)) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./venv/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 1)) (8.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from gdown->-r requirements.txt (line 5)) (3.12.2)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.10/site-packages (from gdown->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from gdown->-r requirements.txt (line 5)) (4.66.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.10/site-packages (from gdown->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 1)) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./venv/lib/python3.10/site-packages (from pydantic<2,>=1->langchain->-r requirements.txt (line 1)) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.10/site-packages (from beautifulsoup4->gdown->-r requirements.txt (line 5)) (2.4.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (1.7.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->-r requirements.txt (line 1)) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Install requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.1.77.tar.gz (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
      "  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
      "  Obtaining dependency information for numpy>=1.20.0 from https://files.pythonhosted.org/packages/c3/ea/1d95b399078ecaa7b5d791e1fdbb3aee272077d9fd5fb499593c87dec5ea/numpy-1.25.2-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading numpy-1.25.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m261.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.77-cp310-cp310-macosx_13_0_arm64.whl size=627309 sha256=752bab84b06b000e9c8c929e4691a841fb14cd10f088c74b2309d40147f1abe8\n",
      "  Stored in directory: /private/var/folders/3m/2xmczshj0c3_khc9dffrxj7r0000gn/T/pip-ephem-wheel-cache-whw5xyyr/wheels/aa/ed/39/87f2ad350dbbf13b600ac744899186b8647c5323c62e2bb348\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: typing-extensions, numpy, diskcache, llama-cpp-python\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "  Attempting uninstall: diskcache\n",
      "    Found existing installation: diskcache 5.6.1\n",
      "    Uninstalling diskcache-5.6.1:\n",
      "      Successfully uninstalled diskcache-5.6.1\n",
      "  Attempting uninstall: llama-cpp-python\n",
      "    Found existing installation: llama-cpp-python 0.1.77\n",
      "    Uninstalling llama-cpp-python-0.1.77:\n",
      "      Successfully uninstalled llama-cpp-python-0.1.77\n",
      "Successfully installed diskcache-5.6.1 llama-cpp-python-0.1.77 numpy-1.25.2 typing-extensions-4.7.1\n"
     ]
    }
   ],
   "source": [
    "# Install llama.cpp python with metal support  https://github.com/abetlen/llama-cpp-python and https://github.com/ggerganov/llama.cpp\n",
    "!CMAKE_ARGS=\"-DLLAMA_METAL=on\" FORCE_CMAKE=1 pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kyousaf/Dev/Development3/github/redis-langchain-chatbot/venv/lib/python3.10/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1tHWB6u3yQCuAgOYc-DxtZ8Mru3uV5_lj\n",
      "From (redirected): https://drive.google.com/uc?id=1tHWB6u3yQCuAgOYc-DxtZ8Mru3uV5_lj&confirm=t&uuid=7573f967-07b7-478d-83d3-1588f8815c00\n",
      "To: /Users/kyousaf/Dev/Development3/github/redis-langchain-chatbot/product_data.csv\n",
      "100%|████████████████████████████████████████| 225M/225M [00:06<00:00, 32.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "!gdown --id 1tHWB6u3yQCuAgOYc-DxtZ8Mru3uV5_lj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MAX_TEXT_LENGTH=512\n",
    "\n",
    "def auto_truncate(val):\n",
    "    \"\"\"Truncate the given text.\"\"\"\n",
    "    return val[:MAX_TEXT_LENGTH]\n",
    "\n",
    "# Load Product data and truncate long text fields\n",
    "all_prods_df = pd.read_csv(\"product_data.csv\", converters={\n",
    "    'bullet_point': auto_truncate,\n",
    "    'item_keywords': auto_truncate,\n",
    "    'item_name': auto_truncate\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "00_n4VWH7FoB",
    "outputId": "f26daa8c-4af9-4def-d5ab-3197777fe2f9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>country</th>\n",
       "      <th>main_image_id</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>bullet_point</th>\n",
       "      <th>item_keywords</th>\n",
       "      <th>material</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>item_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_number</th>\n",
       "      <th>product_type</th>\n",
       "      <th>primary_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B07T6RZ2CM</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>IN</td>\n",
       "      <td>71dZhpsferL</td>\n",
       "      <td>amazon.in</td>\n",
       "      <td>3D Printed Hard Back Case Mobile Cover for Len...</td>\n",
       "      <td>mobile cover back cover mobile case phone case...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon Brand - Solimo</td>\n",
       "      <td>Others</td>\n",
       "      <td>Amazon Brand - Solimo Designer Couples Sitting...</td>\n",
       "      <td>Lenovo K4 Note</td>\n",
       "      <td>gz8115-SL40423</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>B07T6RZ2CM-amazon.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B07T2JY31Y</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>IN</td>\n",
       "      <td>71vX7qIEAIL</td>\n",
       "      <td>amazon.in</td>\n",
       "      <td>3D Printed Hard Back Case Mobile Cover for Son...</td>\n",
       "      <td>mobile cover back cover mobile case phone case...</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Amazon Brand - Solimo</td>\n",
       "      <td>others</td>\n",
       "      <td>Amazon Brand - Solimo Designer Leaf on Wood 3D...</td>\n",
       "      <td>Sony Xperia Z1 L39H</td>\n",
       "      <td>gz8056-SL40528</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>B07T2JY31Y-amazon.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0849YGSCZ</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>AE</td>\n",
       "      <td>A1EZF-2mB5L</td>\n",
       "      <td>amazon.ae</td>\n",
       "      <td></td>\n",
       "      <td>small de fur rooms navidad woven girls shag pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stone &amp; Beam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stone &amp; Beam Contemporary Doily Wool Farmhouse...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I59I8044IVYGRYC00-Parent</td>\n",
       "      <td>HOME_FURNITURE_AND_DECOR</td>\n",
       "      <td>B0849YGSCZ-amazon.ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B081K6TCML</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>IN</td>\n",
       "      <td>81o9EyZ-fAL</td>\n",
       "      <td>amazon.in</td>\n",
       "      <td>Solimo Plastic Multipurpose Modular Drawer; sm...</td>\n",
       "      <td>drawer modular drawer 3 rack modular drawer ki...</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>Amazon Brand - Solimo</td>\n",
       "      <td>Multicolor</td>\n",
       "      <td>Amazon Brand - Solimo Plastic Multipurpose Mod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sol_cujo_13</td>\n",
       "      <td>HOME</td>\n",
       "      <td>B081K6TCML-amazon.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0854774X5</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>IN</td>\n",
       "      <td>81xaJCVnl3L</td>\n",
       "      <td>amazon.in</td>\n",
       "      <td>Snug fit for Nokia 8.1, with perfect cut-outs ...</td>\n",
       "      <td>Back Cover Designer Case Designer Take It Easy...</td>\n",
       "      <td>Silicon</td>\n",
       "      <td>Amazon Brand - Solimo</td>\n",
       "      <td>Multicolor</td>\n",
       "      <td>Amazon Brand - Solimo Designer Take It Easy UV...</td>\n",
       "      <td>Nokia 8.1</td>\n",
       "      <td>UV10714-SL40617</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>B0854774X5-amazon.in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id marketplace country main_image_id domain_name  \\\n",
       "0  B07T6RZ2CM      Amazon      IN   71dZhpsferL   amazon.in   \n",
       "1  B07T2JY31Y      Amazon      IN   71vX7qIEAIL   amazon.in   \n",
       "2  B0849YGSCZ      Amazon      AE   A1EZF-2mB5L   amazon.ae   \n",
       "3  B081K6TCML      Amazon      IN   81o9EyZ-fAL   amazon.in   \n",
       "4  B0854774X5      Amazon      IN   81xaJCVnl3L   amazon.in   \n",
       "\n",
       "                                        bullet_point  \\\n",
       "0  3D Printed Hard Back Case Mobile Cover for Len...   \n",
       "1  3D Printed Hard Back Case Mobile Cover for Son...   \n",
       "2                                                      \n",
       "3  Solimo Plastic Multipurpose Modular Drawer; sm...   \n",
       "4  Snug fit for Nokia 8.1, with perfect cut-outs ...   \n",
       "\n",
       "                                       item_keywords material  \\\n",
       "0  mobile cover back cover mobile case phone case...      NaN   \n",
       "1  mobile cover back cover mobile case phone case...     Wood   \n",
       "2  small de fur rooms navidad woven girls shag pa...      NaN   \n",
       "3  drawer modular drawer 3 rack modular drawer ki...  Plastic   \n",
       "4  Back Cover Designer Case Designer Take It Easy...  Silicon   \n",
       "\n",
       "                   brand       color  \\\n",
       "0  Amazon Brand - Solimo      Others   \n",
       "1  Amazon Brand - Solimo      others   \n",
       "2           Stone & Beam         NaN   \n",
       "3  Amazon Brand - Solimo  Multicolor   \n",
       "4  Amazon Brand - Solimo  Multicolor   \n",
       "\n",
       "                                           item_name           model_name  \\\n",
       "0  Amazon Brand - Solimo Designer Couples Sitting...       Lenovo K4 Note   \n",
       "1  Amazon Brand - Solimo Designer Leaf on Wood 3D...  Sony Xperia Z1 L39H   \n",
       "2  Stone & Beam Contemporary Doily Wool Farmhouse...                  NaN   \n",
       "3  Amazon Brand - Solimo Plastic Multipurpose Mod...                  NaN   \n",
       "4  Amazon Brand - Solimo Designer Take It Easy UV...            Nokia 8.1   \n",
       "\n",
       "               model_number              product_type           primary_key  \n",
       "0            gz8115-SL40423       CELLULAR_PHONE_CASE  B07T6RZ2CM-amazon.in  \n",
       "1            gz8056-SL40528       CELLULAR_PHONE_CASE  B07T2JY31Y-amazon.in  \n",
       "2  I59I8044IVYGRYC00-Parent  HOME_FURNITURE_AND_DECOR  B0849YGSCZ-amazon.ae  \n",
       "3               sol_cujo_13                      HOME  B081K6TCML-amazon.in  \n",
       "4           UV10714-SL40617       CELLULAR_PHONE_CASE  B0854774X5-amazon.in  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contruct a primary key from item ID and domain name\n",
    "all_prods_df['primary_key'] = (\n",
    "    all_prods_df['item_id'] + '-' + all_prods_df['domain_name']\n",
    ")\n",
    "# Replace empty strings with None and drop\n",
    "all_prods_df['item_keywords'].replace('', None, inplace=True)\n",
    "all_prods_df.dropna(subset=['item_keywords'], inplace=True)\n",
    "\n",
    "# Reset pandas dataframe index\n",
    "all_prods_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "all_prods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Num products to use (subset)\n",
    "NUMBER_PRODUCTS = 2500  \n",
    "\n",
    "# Get the first 1000 products with non-empty item keywords\n",
    "product_metadata = ( \n",
    "    all_prods_df\n",
    "     .head(NUMBER_PRODUCTS)\n",
    "     .to_dict(orient='index')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Iw7rlppY8f3a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_id': 'B07T6RZ2CM',\n",
       " 'marketplace': 'Amazon',\n",
       " 'country': 'IN',\n",
       " 'main_image_id': '71dZhpsferL',\n",
       " 'domain_name': 'amazon.in',\n",
       " 'bullet_point': '3D Printed Hard Back Case Mobile Cover for Lenovo K4 Note Easy to put & take off with perfect cutouts for volume buttons, audio & charging ports. Stylish design and appearance, express your unique personality. Extreme precision design allows easy access to all buttons and ports while featuring raised bezel to life screen and camera off flat surface. Slim Hard Back Cover No Warranty None',\n",
       " 'item_keywords': 'mobile cover back cover mobile case phone case mobile panel phone panel Lenovo mobile case Lenovo phone cover Lenovo back case hard case 3D printed mobile cover mobile cover back cover mobile case phone case mobile panel phone panel Lenovo mobile case Lenovo phone cover Lenovo back case hard case 3D printed mobile cover mobile cover back cover mobile case phone case mobile panel phone panel Lenovo mobile case Lenovo phone cover Lenovo back case hard case 3D printed mobile cover mobile cover back cover mobil',\n",
       " 'material': nan,\n",
       " 'brand': 'Amazon Brand - Solimo',\n",
       " 'color': 'Others',\n",
       " 'item_name': 'Amazon Brand - Solimo Designer Couples Sitting at Dark 3D Printed Hard Back Case Mobile Cover for Lenovo K4 Note',\n",
       " 'model_name': 'Lenovo K4 Note',\n",
       " 'model_number': 'gz8115-SL40423',\n",
       " 'product_type': 'CELLULAR_PHONE_CASE',\n",
       " 'primary_key': 'B07T6RZ2CM-amazon.in'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check one of the products\n",
    "product_metadata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Redis as a vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyousaf/Dev/Development3/github/redis-langchain-chatbot/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.redis import Redis as RedisVectorStore\n",
    "\n",
    "# data that will be embedded and converted to vectors\n",
    "texts = [\n",
    "    v['item_name'] for k, v in product_metadata.items()\n",
    "]\n",
    "\n",
    "# product metadata that we'll store along our vectors\n",
    "metadatas = list(product_metadata.values())\n",
    "# we will use HuggingFace as our embeddings provider\n",
    "embedding = HuggingFaceEmbeddings()\n",
    "\n",
    "# name of the Redis search index to create\n",
    "index_name = \"products\"\n",
    "\n",
    "# assumes you have a redis stack server running on within your docker compose network\n",
    "redis_url = \"redis://127.0.0.1:6379\"\n",
    "\n",
    "# create and load redis with documents\n",
    "vectorstore = RedisVectorStore.from_texts(\n",
    "    texts=texts,\n",
    "    metadatas=metadatas,\n",
    "    embedding=embedding,\n",
    "    index_name=index_name,\n",
    "    redis_url=redis_url\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the ChatBot with ConversationalRetrieverChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/kyousaf//.cache/lm-studio/models/thebloke/llama-2-13b-chat.ggml/llama-2-13b-chat.ggmlv3.q6_K.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 4096\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_head_kv  = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 1.0e-06\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 18 (mostly Q6_K)\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.11 MB\n",
      "llama_model_load_internal: mem required  = 10848.82 MB (+ 3200.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 3200.00 MB\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: using MPS\n",
      "ggml_metal_init: loading '/Users/kyousaf/Dev/Development3/github/redis-langchain-chatbot/venv/lib/python3.10/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x28e11b170\n",
      "ggml_metal_init: loaded kernel_add_row                        0x28e11b5d0\n",
      "ggml_metal_init: loaded kernel_mul                            0x28e11b830\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x28e11ba90\n",
      "ggml_metal_init: loaded kernel_scale                          0x28e11bcf0\n",
      "ggml_metal_init: loaded kernel_silu                           0x28e11bf50\n",
      "ggml_metal_init: loaded kernel_relu                           0x28e11c370\n",
      "ggml_metal_init: loaded kernel_gelu                           0x28e11c790\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x28e11cbb0\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x28e11cfd0\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x28e11d3f0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x28e11d810\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x28e11dc30\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                  0x28e11e050\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                  0x28e11e470\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                  0x28e11e890\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                  0x28e11ecb0\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                  0x28e11f0d0\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x28e11f4f0\n",
      "ggml_metal_init: loaded kernel_norm                           0x28e11fba0\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x28e120300\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x28e1208c0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x28e120e80\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x28e121440\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x28e121a00\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x28e121fc0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x28e1223e0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x28e122a00\n",
      "ggml_metal_init: loaded kernel_rope                           0x28e122e20\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x28e1235e0\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x28e123d70\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x28e124500\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x28e11f910\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize = 49152.00 MB\n",
      "ggml_metal_init: hasUnifiedMemory             = true\n",
      "ggml_metal_init: maxTransferRate              = built-in GPU\n",
      "llama_new_context_with_model: max tensor size =   128.17 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size = 10184.16 MB, (10184.61 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'eval            ' buffer, size =    12.00 MB, (10196.61 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  3202.00 MB, (13398.61 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'scr0            ' buffer, size =   461.00 MB, (13859.61 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'scr1            ' buffer, size =   192.00 MB, (14051.61 / 49152.00)\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import (\n",
    "    ConversationalRetrievalChain,\n",
    "    LLMChain\n",
    ")\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"Given the following chat history and a follow up question, rephrase the follow up input question to be a standalone question.\n",
    "Or end the conversation if it seems like it's done.\n",
    "\n",
    "Chat History:\\\"\"\"\n",
    "{chat_history}\n",
    "\\\"\"\"\n",
    "\n",
    "Follow Up Input: \\\"\"\"\n",
    "{question}\n",
    "\\\"\"\"\n",
    "\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "condense_question_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "template = \"\"\"You are a friendly, conversational retail shopping assistant. Use the following context including product names, descriptions, and keywords to show the shopper whats available, help find what they want, and answer any questions.\n",
    "It's ok if you don't know the answer.\n",
    "\n",
    "Context:\\\"\"\"\n",
    "{context}\n",
    "\\\"\"\"\n",
    "\n",
    "Question:\\\"\n",
    "\\\"\"\"\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "qa_prompt= PromptTemplate.from_template(template)\n",
    "\n",
    "# llma configuration\n",
    "#langchain.debug = True\n",
    "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "n_ctx = 4096\n",
    "n_batch = 4096 # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "\n",
    "\n",
    "#We will just use one streaming llm\n",
    "llm = LlamaCpp(\n",
    "   model_path=\"/Users/kyousaf//.cache/lm-studio/models/thebloke/llama-2-13b-chat.ggml/llama-2-13b-chat.ggmlv3.q6_K.bin\",\n",
    "   n_gpu_layers=n_gpu_layers,\n",
    "   n_batch=n_batch,\n",
    "   n_ctx = n_ctx,\n",
    "   f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=CallbackManager([\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]),\n",
    "   verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "# use the LLM Chain to create a question creation chain\n",
    "question_generator = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=condense_question_prompt\n",
    ")\n",
    "\n",
    "# use the streaming LLM to create a question answering chain\n",
    "doc_chain = load_qa_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=qa_prompt\n",
    ")\n",
    "\n",
    "\n",
    "chatbot = ConversationalRetrievalChain(\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    combine_docs_chain=doc_chain,\n",
    "    question_generator=question_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hi! What are you looking for today? shoes\n"
     ]
    }
   ],
   "source": [
    "# create a chat history buffer\n",
    "chat_history = []\n",
    "langchain.debug = False\n",
    "\n",
    "# gather user input for the first question to kick off the bot\n",
    "question = input(\"Hi! What are you looking for today?\")\n",
    "\n",
    "# keep the bot running in a loop to simulate a conversation\n",
    "while True:\n",
    "    result = chatbot(\n",
    "        {\"question\": question, \"chat_history\": chat_history}\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    chat_history.append((result[\"question\"], result[\"answer\"]))\n",
    "    question = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize your chains for even better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain.schema import BaseRetriever\n",
    "from langchain.vectorstores import VectorStore\n",
    "from langchain.schema import Document\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class RedisProductRetriever(BaseRetriever, BaseModel):\n",
    "    vectorstore: VectorStore\n",
    "\n",
    "    class Config:\n",
    "        \n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def combine_metadata(self, doc) -> str:\n",
    "        metadata = doc.metadata\n",
    "        return (\n",
    "            \"Item Name: \" + metadata[\"item_name\"] + \". \" +\n",
    "            \"Item Description: \" + metadata[\"bullet_point\"] + \". \" +\n",
    "            \"Item Keywords: \" + metadata[\"item_keywords\"] + \".\"\n",
    "        )\n",
    "\n",
    "    def get_relevant_documents(self, query):\n",
    "        docs = []\n",
    "        for doc in self.vectorstore.similarity_search(query):\n",
    "            content = self.combine_metadata(doc)\n",
    "            docs.append(Document(\n",
    "                page_content=content,\n",
    "                metadata=doc.metadata\n",
    "            ))\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup ChatBot with new retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "redis_product_retriever = RedisProductRetriever(vectorstore=vectorstore)\n",
    "\n",
    "chatbot = ConversationalRetrievalChain(\n",
    "    retriever=redis_product_retriever,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    question_generator=question_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a chat history buffer\n",
    "chat_history = []\n",
    "\n",
    "# gather user input for the first question to kick off the bot\n",
    "question = input(\"Hi! What are you looking for today?\")\n",
    "\n",
    "# keep the bot running in a loop to simulate a conversation\n",
    "while True:\n",
    "    result = chatbot(\n",
    "        {\"question\": question, \"chat_history\": chat_history}\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "    chat_history.append((result[\"question\"], result[\"answer\"]))\n",
    "    question = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
